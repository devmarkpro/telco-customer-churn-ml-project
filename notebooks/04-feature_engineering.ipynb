{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from jupyter_server.utils import fetch\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from datetime import datetime\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "K_FOLDS = 5\n",
    "RESULT_PATH = \"../results/\"\n",
    "RESULT_FINE_NAME = \"model_comparison_results.\"\n",
    "RESULT_FINE_EXT = \"csv\"\n",
    "DATASET_PATH = \"../data/Telco-Customer-Churn.csv\"\n",
    "TEST_SIZE = 0.2\n",
    "TARGET_COLUMN = \"Churn\"\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(\n",
    "        filepath: str,\n",
    "        drop_aux=False,\n",
    "        encode_binary=False,\n",
    "        map_gender=False,\n",
    "        one_hot_encoding=False,\n",
    "        scale_numeric=False,\n",
    "        to_numeric=False,\n",
    "        encode_target=True,\n",
    ") -> pd.DataFrame:\n",
    "    churn_df = pd.read_csv(filepath)\n",
    "    if drop_aux:\n",
    "        # Drop customerID\n",
    "        churn_df = churn_df.drop(columns=[\"customerID\"])\n",
    "\n",
    "    if to_numeric:\n",
    "        # Convert TotalCharges to numeric and drop missing values\n",
    "        churn_df[\"TotalCharges\"] = pd.to_numeric(\n",
    "            churn_df[\"TotalCharges\"], errors=\"coerce\"\n",
    "        )\n",
    "        churn_df = churn_df.dropna(subset=[\"TotalCharges\"])\n",
    "\n",
    "    if encode_binary:\n",
    "        # Encode binary features\n",
    "        binary_cols = [\"Partner\", \"Dependents\", \"PhoneService\", \"PaperlessBilling\"]\n",
    "        for col in binary_cols:\n",
    "            churn_df[col] = churn_df[col].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "    if encode_target:\n",
    "        # Encode target variable\n",
    "        churn_df[\"Churn\"] = churn_df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "    if map_gender:\n",
    "        # Map gender\n",
    "        churn_df[\"gender\"] = churn_df[\"gender\"].map({\"Male\": 1, \"Female\": 0})\n",
    "\n",
    "    if one_hot_encoding:\n",
    "        # One-hot encode remaining categorical variables\n",
    "        categorical_cols = churn_df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "        churn_df = pd.get_dummies(churn_df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    if scale_numeric:\n",
    "        # Scale numeric features\n",
    "        numeric_cols = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
    "        scaler = StandardScaler()\n",
    "        churn_df[numeric_cols] = scaler.fit_transform(churn_df[numeric_cols])\n",
    "\n",
    "    return churn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Feature engineering means creating new features or changing existing ones to help the model learn better. It can improve the modelâ€™s performance by showing patterns in the data that are not easy to see at first.\n",
    "\n",
    "In this part, we create an **interaction feature** using two numerical columns. An interaction feature helps the model understand how two values work together.\n",
    "\n",
    "### Create Interaction Feature\n",
    "\n",
    "We added a new feature: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (no new feature)</th>\n",
       "      <td>0.786780</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.513369</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.832006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (with interaction feature)</th>\n",
       "      <td>0.788913</td>\n",
       "      <td>0.623794</td>\n",
       "      <td>0.518717</td>\n",
       "      <td>0.566423</td>\n",
       "      <td>0.832066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                accuracy  precision    recall  \\\n",
       "Logistic Regression (no new feature)            0.786780   0.619355  0.513369   \n",
       "Logistic Regression (with interaction feature)  0.788913   0.623794  0.518717   \n",
       "\n",
       "                                                      f1   roc_auc  \n",
       "Logistic Regression (no new feature)            0.561404  0.832006  \n",
       "Logistic Regression (with interaction feature)  0.566423  0.832066  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load and preprocess data\n",
    "df = load_and_preprocess(\n",
    "    filepath=DATASET_PATH,\n",
    "    drop_aux=True,\n",
    "    encode_binary=True,\n",
    "    map_gender=True,\n",
    "    one_hot_encoding=True,\n",
    "    scale_numeric=True,\n",
    "    to_numeric=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Split features/target\n",
    "X = df.drop(columns=[TARGET_COLUMN])\n",
    "y = df[TARGET_COLUMN]\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "num_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# Model 1: Baseline Logistic Regression\n",
    "lr1 = LogisticRegression(random_state=42, max_iter=500)\n",
    "lr1.fit(X_train, y_train)\n",
    "y_pred1 = lr1.predict(X_test)\n",
    "y_proba1 = lr1.predict_proba(X_test)[:, 1]\n",
    "\n",
    "results = {}\n",
    "results[\"Logistic Regression (no new feature)\"] = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred1),\n",
    "    \"precision\": precision_score(y_test, y_pred1),\n",
    "    \"recall\": recall_score(y_test, y_pred1),\n",
    "    \"f1\": f1_score(y_test, y_pred1),\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_proba1),\n",
    "}\n",
    "\n",
    "# Model 2: With Interaction Feature\n",
    "X_train2 = X_train.copy()\n",
    "X_test2 = X_test.copy()\n",
    "X_train2['tenure_MonthlyCharges'] = X_train2['tenure'] * X_train2['MonthlyCharges']\n",
    "X_test2['tenure_MonthlyCharges'] = X_test2['tenure'] * X_test2['MonthlyCharges']\n",
    "\n",
    "lr2 = LogisticRegression(random_state=42, max_iter=500)\n",
    "lr2.fit(X_train2, y_train)\n",
    "y_pred2 = lr2.predict(X_test2)\n",
    "y_proba2 = lr2.predict_proba(X_test2)[:, 1]\n",
    "\n",
    "results[\"Logistic Regression (with interaction feature)\"] = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred2),\n",
    "    \"precision\": precision_score(y_test, y_pred2),\n",
    "    \"recall\": recall_score(y_test, y_pred2),\n",
    "    \"f1\": f1_score(y_test, y_pred2),\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_proba2),\n",
    "}\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.to_csv('../results/logreg_feature_engineering_comparison.csv')\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csca-5622-supervised-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
